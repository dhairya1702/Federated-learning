
# ğŸš€ Federated Learning with Flower & PyTorch on MNIST  

This project demonstrates a **federated learning** setup using **Flower** ğŸŒ¸ and **PyTorch** ğŸ”¥.  
The **MNIST dataset** ğŸ–¼ï¸ is partitioned across multiple clients, each training a model on their local data before sending updates to the central **server** ğŸ–¥ï¸ for aggregation.  

To simulate **adversarial clients**, **Clients 9 & 10** contain **poisoned data** ğŸ§ª (label flipping).  

The server implements a **Trust and Reputation Mechanism** ğŸ† to mitigate their influence.

---

## âš™ï¸ Setup & Requirements 

1. **Dependencies**:
   - Python 3.7+
   - Install the required libraries:
     ```bash
     pip install flwr torch torchvision matplotlib pandas
     ```

2. **Folder Structure**:
   - Place this script and all code files in a single directory.
   - Ensure a subdirectory called `data/mnist/` exists within this directory to store the MNIST dataset.
   - 

## ğŸ“Š Data Preparation

1. **ğŸ“‰ Download and Partition the MNIST Dataset**:
   - Run `prepare_data.py` to download the MNIST dataset and split it into partitions for each client:
     ```bash
     python prepare_data.py
     ```
This will:

     âœ… Download the MNIST dataset ğŸ–¼ï¸
     âœ… Create 10 partitions inside data/mnist/ ğŸ“‚
     âœ… Poison Clients 9 & 10 with random label flipping ğŸ§ª


## ğŸ” Code Overview  

### ğŸ–¥ï¸ **Server Code** (`server.py`)  
- Initializes and starts the **Flower Federated Learning Server** ğŸŒ¸.  
- Implements a **custom aggregation strategy** with **Trust & Reputation mechanisms** ğŸ†.  
- Generates **accuracy & loss plots** ğŸ“Š.  

### ğŸ¤– **Client Code** (`client.py`)  
- Each client trains a **PyTorch-based model** locally and communicates with the server.  
- **Clients 9 & 10** contain **poisoned data** for adversarial testing ğŸ§ª.  

## ğŸš€ Running the Code  

1. **ğŸ Start the Server**:
   - Open a terminal and run the server:
     ```bash
     python server.py
     ```

2. **ğŸ¤– Start the Clients**:
   - In separate terminals, start each client by setting a unique client ID:
     ```bash
     CLIENT_ID=0 python client.py
     CLIENT_ID=1 python client.py
     ...
     CLIENT_ID=9 python client.py
     ```
   - You need 10 terminals or terminal tabs to start each client with IDs from 0 to 9. 

## ğŸ“ˆ Results & Plots  

After all **federated rounds** complete, the **server** will generate the following visualizations:  

ğŸ”¹ **Loss Trends**  
   - ğŸ“‰ **Loss per client** over rounds  
   - ğŸ“Š **Average loss** across all clients  

ğŸ”¹ **Accuracy Trends**  
   - âœ… **Evaluation accuracy per client** over rounds  
   - ğŸ“ˆ **Average evaluation accuracy** among all clients  

These plots help **analyze model performance** and the **impact of poisoned clients** on federated learning.  

